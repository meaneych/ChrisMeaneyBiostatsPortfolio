{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "SimpleTransformers_T5_QA_MedQuestionAnswer_June2021.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "71a62f5b53c4405191b6b98d1eabe576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0397f0a559d841bf981389d7f812e392",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e5c704a5a1674eacb71db22be453575f",
              "IPY_MODEL_3e83e18df2764f9da2e4f59eea1d7374",
              "IPY_MODEL_30c789861ead4c83b59034d89f7469d8"
            ]
          }
        },
        "0397f0a559d841bf981389d7f812e392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5c704a5a1674eacb71db22be453575f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8eb7559e5aa74e7db9f0bbc59b807c14",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbd59b07854946a593730d2ed98afcbe"
          }
        },
        "3e83e18df2764f9da2e4f59eea1d7374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ccb96cc9ae14420298302d75a3d80513",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3717bbcaa8742449858347516d21a62"
          }
        },
        "30c789861ead4c83b59034d89f7469d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c477172a7124ccf92eb41c97581281f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 22.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9988c6998d74be09b21b411b5d99142"
          }
        },
        "8eb7559e5aa74e7db9f0bbc59b807c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbd59b07854946a593730d2ed98afcbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccb96cc9ae14420298302d75a3d80513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3717bbcaa8742449858347516d21a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c477172a7124ccf92eb41c97581281f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9988c6998d74be09b21b411b5d99142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8288ddcad5d43dfbc7f7c103856754b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_db45aea46b4f42568937d8ad354268d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_390feb660ab84964b920af22593c36ce",
              "IPY_MODEL_4d0d145fd6d047448e943358f44fa896",
              "IPY_MODEL_d7623fea3c844fcb875417cf34114ecf"
            ]
          }
        },
        "db45aea46b4f42568937d8ad354268d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "390feb660ab84964b920af22593c36ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1cad7e763e374d868b95518eb9b1874c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a14d77929a44b609afd4b6a1a9cb1d3"
          }
        },
        "4d0d145fd6d047448e943358f44fa896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6de1d4a1ea294bccaef113d99cc2162b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891691430,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891691430,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da5e503f0e0b439686656f11f7d676b4"
          }
        },
        "d7623fea3c844fcb875417cf34114ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa791488108a4d6da31775ae560a14b3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:26&lt;00:00, 34.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cec73289665478e9249d4a282ba52e4"
          }
        },
        "1cad7e763e374d868b95518eb9b1874c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a14d77929a44b609afd4b6a1a9cb1d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6de1d4a1ea294bccaef113d99cc2162b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da5e503f0e0b439686656f11f7d676b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa791488108a4d6da31775ae560a14b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cec73289665478e9249d4a282ba52e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70b0809374a244a38272feab285b84ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8371da6918064dee8b4eee6d420e8e72",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cc5f8766ecc3430bb9d1276bde24ad29",
              "IPY_MODEL_783e2fd6a38c44e59aecb320aa0d5b01",
              "IPY_MODEL_0c4e35850d184c7080f99f3fefd99f8c"
            ]
          }
        },
        "8371da6918064dee8b4eee6d420e8e72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc5f8766ecc3430bb9d1276bde24ad29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65f00143409c4420a906635c02822ea7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9394e89f1cbc456c9854f90f8e6ae3d8"
          }
        },
        "783e2fd6a38c44e59aecb320aa0d5b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a7b76636311048f9aa25e83c9d80bd39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_952de5fde21a44d3a9146a366e892476"
          }
        },
        "0c4e35850d184c7080f99f3fefd99f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_232d8773d5c34a9daa3badb1292982df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:00&lt;00:00, 1.11MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34481195bb25481fabe381226a8c95df"
          }
        },
        "65f00143409c4420a906635c02822ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9394e89f1cbc456c9854f90f8e6ae3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7b76636311048f9aa25e83c9d80bd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "952de5fde21a44d3a9146a366e892476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "232d8773d5c34a9daa3badb1292982df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34481195bb25481fabe381226a8c95df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d7b8f4e3caf4b02a85998dde53df922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5dd76f20877849e4b24648b29ed047df",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aac3529404544f7a9a020911e45c2164",
              "IPY_MODEL_890a275ec6bc452c99e6b08ab542fd6d",
              "IPY_MODEL_d35f10c7b3eb48c59bf285089d9834ac"
            ]
          }
        },
        "5dd76f20877849e4b24648b29ed047df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aac3529404544f7a9a020911e45c2164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_67a6238c3a754133bab1187d023ac596",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_edb2515a768b4b70b39268f8a64e73c2"
          }
        },
        "890a275ec6bc452c99e6b08ab542fd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da41c805b5304e508030cad0cd8cd4da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1389353,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1389353,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a08d734c26e440699cda73a189491968"
          }
        },
        "d35f10c7b3eb48c59bf285089d9834ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2821a3b85d034b1f81578ffb59fc8a58",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 2.63MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ac9ce5d7f4f4759a9e189d5449dee36"
          }
        },
        "67a6238c3a754133bab1187d023ac596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "edb2515a768b4b70b39268f8a64e73c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da41c805b5304e508030cad0cd8cd4da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a08d734c26e440699cda73a189491968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2821a3b85d034b1f81578ffb59fc8a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ac9ce5d7f4f4759a9e189d5449dee36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_7w7lBnijmo"
      },
      "source": [
        "############################################################################\n",
        "##  Simple transformers Python t5 Module - Example of medical/answer using T5 encoder/decoder model   \n",
        "##  https://simpletransformers.ai/docs/usage/\n",
        "##\n",
        "## Training data is parsed from:\n",
        "## https://med-mu.com/wp-content/uploads/2018/06/medsouls.blogspot.com-1000-Questions-and-Answers-from-Kumar-_-Clark_s-Clinical-Medicine-2e-Saunders-2011.pdf\n",
        "##\n",
        "## Author: Chris Meaney\n",
        "## Date: June 2021 \n",
        "############################################################################"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wePv3-PdnNuJ"
      },
      "source": [
        "## Delete check-pointed files (else disk fills up) \n",
        "## Note: these are BASH commands (not python anymore)\n",
        "!rm -rf outputs/check*"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf6z99smijmt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb93a662-daec-438e-c27a-01d8d47cbace"
      },
      "source": [
        "##########################\n",
        "## Dependency modules\n",
        "##########################\n",
        "\n",
        "## Pandas for data wrangling\n",
        "import pandas as pd\n",
        "\n",
        "## matplotlib plotting\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "## Numpy for numerics\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "## sklearn for train/val/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Simple Transformers\n",
        "!pip install --quiet tokenizers\n",
        "!pip install --quiet transformers -U\n",
        "!pip install --quiet simpletransformers\n",
        "from scipy.special import softmax\n",
        "from simpletransformers.t5 import T5Model, T5Args\n",
        "\n",
        "## For system info\n",
        "!pip install --quiet sinfo\n",
        "from sinfo import sinfo"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.3MB 12.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3MB 12.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 37.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 225kB 11.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8MB 20.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2MB 36.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 42.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 32.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 42.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 9.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 45.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 11.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 44.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2MB 31.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 45.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 9.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 44.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 45.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 46.2MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datasets 1.7.0 has requirement tqdm<4.50.0,>=4.27, but you'll have tqdm 4.61.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.1MB/s \n",
            "\u001b[?25h  Building wheel for sinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkzkksDwijmu"
      },
      "source": [
        "## Options for printing more rows/columns in Jupyter Notebook\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 100)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46cMe_vOijmv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "24e60467-5bdb-4e9b-93dd-b45368bcdce0"
      },
      "source": [
        "\n",
        "##########################################################\n",
        "## Use pandas to import data, and store as data.frame\n",
        "##########################################################\n",
        "\n",
        "## Read in data from Google Drive account (this will force mount step, authentication step, etc.)\n",
        "## https://stackoverflow.com/questions/48340341/how-to-read-csv-to-dataframe-in-google-colab\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "import pandas as pd \n",
        "dat = pd.read_csv('gdrive/My Drive/ColabData/KumarClark_2011_1000ClinicalQuestionsAnswered_Parsed.csv', encoding='latin1')\n",
        "dat.head(n=15)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>QUESTION1 regarding medical ethics, if a man i...</td>\n",
              "      <td>ANSWER1 no. the doctor can only give confident...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>QUESTION2 is it unlawful in most countries to ...</td>\n",
              "      <td>ANSWER2 in all healthcare systems, rationing h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>QUESTION3 what is meant by qalys? is there a d...</td>\n",
              "      <td>ANSWER3 qalys are quality adjusted life years....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>QUESTION4 are âdo not resuscitateâ orders ...</td>\n",
              "      <td>ANSWER4 it is accepted in most countries that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>QUESTION5 what is a living will?</td>\n",
              "      <td>ANSWER5 this is a written advanced directive m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>QUESTION8 as a junior doctor, i have to attend...</td>\n",
              "      <td>ANSWER8 your patients must always be informed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>QUESTION9 is the role of the advocate in a med...</td>\n",
              "      <td>ANSWER9 both! however, an advocate represents ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>QUESTION10 we are always asked by our seniors ...</td>\n",
              "      <td>ANSWER10 the law in the uk is clear: touching ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>QUESTION1 as cells grow and regenerate, what m...</td>\n",
              "      <td>ANSWER1 cells are continually dying by a proce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>QUESTION2 i cannot find out why some of the au...</td>\n",
              "      <td>ANSWER2 by definition, the genes responsible f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>QUESTION3 we have been told that some tumours ...</td>\n",
              "      <td>ANSWER3 microsatellites are short sequences of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>QUESTION4 i understand that microarrays are be...</td>\n",
              "      <td>ANSWER4 microarrays are, as you say, used to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>QUESTION5 why do mitochondrial diseases cause ...</td>\n",
              "      <td>ANSWER5 muscles derive energy via oxidative ph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>QUESTION6 why do successive generations of pat...</td>\n",
              "      <td>ANSWER6 this process is called âgenetic anti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>QUESTION7 does a normal serum uric acid level ...</td>\n",
              "      <td>ANSWER7 a raised serum uric acid level is usua...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            questions  \\\n",
              "0   QUESTION1 regarding medical ethics, if a man i...   \n",
              "1   QUESTION2 is it unlawful in most countries to ...   \n",
              "2   QUESTION3 what is meant by qalys? is there a d...   \n",
              "3   QUESTION4 are âdo not resuscitateâ orders ...   \n",
              "4                    QUESTION5 what is a living will?   \n",
              "5   QUESTION8 as a junior doctor, i have to attend...   \n",
              "6   QUESTION9 is the role of the advocate in a med...   \n",
              "7   QUESTION10 we are always asked by our seniors ...   \n",
              "8   QUESTION1 as cells grow and regenerate, what m...   \n",
              "9   QUESTION2 i cannot find out why some of the au...   \n",
              "10  QUESTION3 we have been told that some tumours ...   \n",
              "11  QUESTION4 i understand that microarrays are be...   \n",
              "12  QUESTION5 why do mitochondrial diseases cause ...   \n",
              "13  QUESTION6 why do successive generations of pat...   \n",
              "14  QUESTION7 does a normal serum uric acid level ...   \n",
              "\n",
              "                                              answers  \n",
              "0   ANSWER1 no. the doctor can only give confident...  \n",
              "1   ANSWER2 in all healthcare systems, rationing h...  \n",
              "2   ANSWER3 qalys are quality adjusted life years....  \n",
              "3   ANSWER4 it is accepted in most countries that ...  \n",
              "4   ANSWER5 this is a written advanced directive m...  \n",
              "5   ANSWER8 your patients must always be informed ...  \n",
              "6   ANSWER9 both! however, an advocate represents ...  \n",
              "7   ANSWER10 the law in the uk is clear: touching ...  \n",
              "8   ANSWER1 cells are continually dying by a proce...  \n",
              "9   ANSWER2 by definition, the genes responsible f...  \n",
              "10  ANSWER3 microsatellites are short sequences of...  \n",
              "11  ANSWER4 microarrays are, as you say, used to a...  \n",
              "12  ANSWER5 muscles derive energy via oxidative ph...  \n",
              "13  ANSWER6 this process is called âgenetic anti...  \n",
              "14  ANSWER7 a raised serum uric acid level is usua...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "Yco8lMC5uxor",
        "outputId": "0e89abc0-a875-40ce-eeb1-136014ae5ef3"
      },
      "source": [
        "## Remove QUESTION/ANSWER labels from header of text strings\n",
        "dat['questions'] = dat.questions.replace(to_replace='^QUESTION[0-9]+ ', value='', regex=True)\n",
        "dat['answers'] = dat.answers.replace(to_replace='^ANSWER[0-9]+ ', value='', regex=True)\n",
        "## Add prefix column\n",
        "dat['prefix'] = 'ask_question'\n",
        "## Clean up column names\n",
        "dat.columns = ['input_text','target_text','prefix']\n",
        "## Re-order column order\n",
        "col_order = ['prefix','input_text','target_text']\n",
        "dat = dat[col_order]\n",
        "## Print first couple rows of new dataset\n",
        "dat.head(n=15)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prefix</th>\n",
              "      <th>input_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>regarding medical ethics, if a man is discover...</td>\n",
              "      <td>no. the doctor can only give confidential info...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>is it unlawful in most countries to limit medi...</td>\n",
              "      <td>in all healthcare systems, rationing has becom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>what is meant by qalys? is there a difference ...</td>\n",
              "      <td>qalys are quality adjusted life years. these w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>are âdo not resuscitateâ orders illegal in...</td>\n",
              "      <td>it is accepted in most countries that âfutil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>what is a living will?</td>\n",
              "      <td>this is a written advanced directive made by c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>as a junior doctor, i have to attend many mult...</td>\n",
              "      <td>your patients must always be informed about th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>is the role of the advocate in a medical inter...</td>\n",
              "      <td>both! however, an advocate represents the valu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>we are always asked by our seniors to make sur...</td>\n",
              "      <td>the law in the uk is clear: touching a patient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>as cells grow and regenerate, what mechanism d...</td>\n",
              "      <td>cells are continually dying by a process of ap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>i cannot find out why some of the autosomal do...</td>\n",
              "      <td>by definition, the genes responsible for autos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>we have been told that some tumours in the col...</td>\n",
              "      <td>microsatellites are short sequences of randoml...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>i understand that microarrays are being used t...</td>\n",
              "      <td>microarrays are, as you say, used to analyse g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>why do mitochondrial diseases cause a myopathy?</td>\n",
              "      <td>muscles derive energy via oxidative phosphoryl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>why do successive generations of patients with...</td>\n",
              "      <td>this process is called âgenetic anticipation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ask_question</td>\n",
              "      <td>does a normal serum uric acid level exclude th...</td>\n",
              "      <td>a raised serum uric acid level is usually, but...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          prefix                                         input_text  \\\n",
              "0   ask_question  regarding medical ethics, if a man is discover...   \n",
              "1   ask_question  is it unlawful in most countries to limit medi...   \n",
              "2   ask_question  what is meant by qalys? is there a difference ...   \n",
              "3   ask_question  are âdo not resuscitateâ orders illegal in...   \n",
              "4   ask_question                             what is a living will?   \n",
              "5   ask_question  as a junior doctor, i have to attend many mult...   \n",
              "6   ask_question  is the role of the advocate in a medical inter...   \n",
              "7   ask_question  we are always asked by our seniors to make sur...   \n",
              "8   ask_question  as cells grow and regenerate, what mechanism d...   \n",
              "9   ask_question  i cannot find out why some of the autosomal do...   \n",
              "10  ask_question  we have been told that some tumours in the col...   \n",
              "11  ask_question  i understand that microarrays are being used t...   \n",
              "12  ask_question    why do mitochondrial diseases cause a myopathy?   \n",
              "13  ask_question  why do successive generations of patients with...   \n",
              "14  ask_question  does a normal serum uric acid level exclude th...   \n",
              "\n",
              "                                          target_text  \n",
              "0   no. the doctor can only give confidential info...  \n",
              "1   in all healthcare systems, rationing has becom...  \n",
              "2   qalys are quality adjusted life years. these w...  \n",
              "3   it is accepted in most countries that âfutil...  \n",
              "4   this is a written advanced directive made by c...  \n",
              "5   your patients must always be informed about th...  \n",
              "6   both! however, an advocate represents the valu...  \n",
              "7   the law in the uk is clear: touching a patient...  \n",
              "8   cells are continually dying by a process of ap...  \n",
              "9   by definition, the genes responsible for autos...  \n",
              "10  microsatellites are short sequences of randoml...  \n",
              "11  microarrays are, as you say, used to analyse g...  \n",
              "12  muscles derive energy via oxidative phosphoryl...  \n",
              "13  this process is called âgenetic anticipation...  \n",
              "14  a raised serum uric acid level is usually, but...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfsBrhDRxDWR",
        "outputId": "34616587-1606-467f-b0e8-4464a8ae81a9"
      },
      "source": [
        "## Break into train/evaluation datasets\n",
        "train_data, eval_data = train_test_split(dat, test_size=0.2)\n",
        "[train_data.shape, eval_data.shape]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(688, 3), (172, 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvB2JKjNEdnP"
      },
      "source": [
        "## T5 model configuration arguments\n",
        "model_args = T5Args()\n",
        "\n",
        "## Set T5 model arguments\n",
        "model_args.reprocess_input_data=True\n",
        "model_args.overwrite_output_dir=True\n",
        "model_args.max_seq_length=128\n",
        "model_args.eval_batch_size=16\n",
        "model_args.num_train_epochs=10\n",
        "model_args.save_eval_checkpoints=False\n",
        "model_args.use_multiprocessing=True\n",
        "model_args.silent=True\n",
        "model_args.num_beams=None\n",
        "model_args.do_sample=True\n",
        "model_args.max_length=50\n",
        "model_args.top_k=50\n",
        "model_args.top_p=0.95\n",
        "model_args.num_return_sequences=3"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "janQ4NbNEe8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76020e41-cccd-4c21-96bf-92c5be1ac299"
      },
      "source": [
        "## Can print list of all tunable model hyper-parameters to console\n",
        "help(model_args)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on T5Args in module simpletransformers.config.model_args object:\n",
            "\n",
            "class T5Args(ModelArgs)\n",
            " |  T5Args(adafactor_beta1: float = None, adafactor_clip_threshold: float = 1.0, adafactor_decay_rate: float = -0.8, adafactor_eps: tuple = <factory>, adafactor_relative_step: bool = False, adafactor_scale_parameter: bool = False, adafactor_warmup_init: bool = False, adam_epsilon: float = 1e-08, best_model_dir: str = 'outputs/best_model', cache_dir: str = 'cache_dir/', config: dict = <factory>, cosine_schedule_num_cycles: float = 0.5, custom_layer_parameters: list = <factory>, custom_parameter_groups: list = <factory>, dataloader_num_workers: int = 0, do_lower_case: bool = False, dynamic_quantize: bool = False, early_stopping_consider_epochs: bool = False, early_stopping_delta: float = 0, early_stopping_metric: str = 'eval_loss', early_stopping_metric_minimize: bool = True, early_stopping_patience: int = 3, encoding: str = None, eval_batch_size: int = 8, evaluate_during_training: bool = False, evaluate_during_training_silent: bool = True, evaluate_during_training_steps: int = 2000, evaluate_during_training_verbose: bool = False, evaluate_each_epoch: bool = True, fp16: bool = True, gradient_accumulation_steps: int = 1, learning_rate: float = 0.001, local_rank: int = -1, logging_steps: int = 50, manual_seed: int = None, max_grad_norm: float = 1.0, max_seq_length: int = 128, model_name: str = None, model_type: str = None, multiprocessing_chunksize: int = -1, n_gpu: int = 1, no_cache: bool = False, no_save: bool = False, not_saved_args: list = <factory>, num_train_epochs: int = 1, optimizer: str = 'Adafactor', output_dir: str = 'outputs/', overwrite_output_dir: bool = False, polynomial_decay_schedule_lr_end: float = 1e-07, polynomial_decay_schedule_power: float = 1.0, process_count: int = <factory>, quantized_model: bool = False, reprocess_input_data: bool = True, save_best_model: bool = True, save_eval_checkpoints: bool = True, save_model_every_epoch: bool = True, save_optimizer_and_scheduler: bool = True, save_steps: int = 2000, scheduler: str = 'constant_schedule_with_warmup', silent: bool = False, skip_special_tokens: bool = True, tensorboard_dir: str = None, thread_count: int = None, tokenizer_name: str = None, tokenizer_type: str = None, train_batch_size: int = 8, train_custom_parameters_only: bool = False, use_cached_eval_features: bool = False, use_early_stopping: bool = False, use_hf_datasets: bool = False, use_multiprocessing: bool = True, use_multiprocessing_for_evaluation: bool = True, wandb_kwargs: dict = <factory>, wandb_project: str = None, warmup_ratio: float = 0.06, warmup_steps: int = 0, weight_decay: float = 0.0, model_class: str = 'T5Model', dataset_class: torch.utils.data.dataset.Dataset = None, do_sample: bool = False, early_stopping: bool = True, evaluate_generated_text: bool = False, length_penalty: float = 2.0, max_length: int = 20, max_steps: int = -1, num_beams: int = 1, num_return_sequences: int = 1, preprocess_inputs: bool = True, repetition_penalty: float = 1.0, special_tokens_list: list = <factory>, top_k: float = None, top_p: float = None, use_multiprocessed_decoding: bool = True) -> None\n",
            " |  \n",
            " |  Model args for a T5Model\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      T5Args\n",
            " |      ModelArgs\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __eq__(self, other)\n",
            " |  \n",
            " |  __init__(self, adafactor_beta1: float = None, adafactor_clip_threshold: float = 1.0, adafactor_decay_rate: float = -0.8, adafactor_eps: tuple = <factory>, adafactor_relative_step: bool = False, adafactor_scale_parameter: bool = False, adafactor_warmup_init: bool = False, adam_epsilon: float = 1e-08, best_model_dir: str = 'outputs/best_model', cache_dir: str = 'cache_dir/', config: dict = <factory>, cosine_schedule_num_cycles: float = 0.5, custom_layer_parameters: list = <factory>, custom_parameter_groups: list = <factory>, dataloader_num_workers: int = 0, do_lower_case: bool = False, dynamic_quantize: bool = False, early_stopping_consider_epochs: bool = False, early_stopping_delta: float = 0, early_stopping_metric: str = 'eval_loss', early_stopping_metric_minimize: bool = True, early_stopping_patience: int = 3, encoding: str = None, eval_batch_size: int = 8, evaluate_during_training: bool = False, evaluate_during_training_silent: bool = True, evaluate_during_training_steps: int = 2000, evaluate_during_training_verbose: bool = False, evaluate_each_epoch: bool = True, fp16: bool = True, gradient_accumulation_steps: int = 1, learning_rate: float = 0.001, local_rank: int = -1, logging_steps: int = 50, manual_seed: int = None, max_grad_norm: float = 1.0, max_seq_length: int = 128, model_name: str = None, model_type: str = None, multiprocessing_chunksize: int = -1, n_gpu: int = 1, no_cache: bool = False, no_save: bool = False, not_saved_args: list = <factory>, num_train_epochs: int = 1, optimizer: str = 'Adafactor', output_dir: str = 'outputs/', overwrite_output_dir: bool = False, polynomial_decay_schedule_lr_end: float = 1e-07, polynomial_decay_schedule_power: float = 1.0, process_count: int = <factory>, quantized_model: bool = False, reprocess_input_data: bool = True, save_best_model: bool = True, save_eval_checkpoints: bool = True, save_model_every_epoch: bool = True, save_optimizer_and_scheduler: bool = True, save_steps: int = 2000, scheduler: str = 'constant_schedule_with_warmup', silent: bool = False, skip_special_tokens: bool = True, tensorboard_dir: str = None, thread_count: int = None, tokenizer_name: str = None, tokenizer_type: str = None, train_batch_size: int = 8, train_custom_parameters_only: bool = False, use_cached_eval_features: bool = False, use_early_stopping: bool = False, use_hf_datasets: bool = False, use_multiprocessing: bool = True, use_multiprocessing_for_evaluation: bool = True, wandb_kwargs: dict = <factory>, wandb_project: str = None, warmup_ratio: float = 0.06, warmup_steps: int = 0, weight_decay: float = 0.0, model_class: str = 'T5Model', dataset_class: torch.utils.data.dataset.Dataset = None, do_sample: bool = False, early_stopping: bool = True, evaluate_generated_text: bool = False, length_penalty: float = 2.0, max_length: int = 20, max_steps: int = -1, num_beams: int = 1, num_return_sequences: int = 1, preprocess_inputs: bool = True, repetition_penalty: float = 1.0, special_tokens_list: list = <factory>, top_k: float = None, top_p: float = None, use_multiprocessed_decoding: bool = True) -> None\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __annotations__ = {'adafactor_relative_step': <class 'bool'>, 'adafact...\n",
            " |  \n",
            " |  __dataclass_fields__ = {'adafactor_beta1': Field(name='adafactor_beta1...\n",
            " |  \n",
            " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
            " |  \n",
            " |  __hash__ = None\n",
            " |  \n",
            " |  adafactor_relative_step = False\n",
            " |  \n",
            " |  adafactor_scale_parameter = False\n",
            " |  \n",
            " |  adafactor_warmup_init = False\n",
            " |  \n",
            " |  dataset_class = None\n",
            " |  \n",
            " |  do_sample = False\n",
            " |  \n",
            " |  early_stopping = True\n",
            " |  \n",
            " |  evaluate_generated_text = False\n",
            " |  \n",
            " |  learning_rate = 0.001\n",
            " |  \n",
            " |  length_penalty = 2.0\n",
            " |  \n",
            " |  max_length = 20\n",
            " |  \n",
            " |  max_steps = -1\n",
            " |  \n",
            " |  model_class = 'T5Model'\n",
            " |  \n",
            " |  num_beams = 1\n",
            " |  \n",
            " |  num_return_sequences = 1\n",
            " |  \n",
            " |  optimizer = 'Adafactor'\n",
            " |  \n",
            " |  preprocess_inputs = True\n",
            " |  \n",
            " |  repetition_penalty = 1.0\n",
            " |  \n",
            " |  scheduler = 'constant_schedule_with_warmup'\n",
            " |  \n",
            " |  top_k = None\n",
            " |  \n",
            " |  top_p = None\n",
            " |  \n",
            " |  use_multiprocessed_decoding = True\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from ModelArgs:\n",
            " |  \n",
            " |  get_args_for_saving(self)\n",
            " |  \n",
            " |  load(self, input_dir)\n",
            " |  \n",
            " |  save(self, output_dir)\n",
            " |  \n",
            " |  update_from_dict(self, new_values)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from ModelArgs:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from ModelArgs:\n",
            " |  \n",
            " |  adafactor_beta1 = None\n",
            " |  \n",
            " |  adafactor_clip_threshold = 1.0\n",
            " |  \n",
            " |  adafactor_decay_rate = -0.8\n",
            " |  \n",
            " |  adam_epsilon = 1e-08\n",
            " |  \n",
            " |  best_model_dir = 'outputs/best_model'\n",
            " |  \n",
            " |  cache_dir = 'cache_dir/'\n",
            " |  \n",
            " |  cosine_schedule_num_cycles = 0.5\n",
            " |  \n",
            " |  dataloader_num_workers = 0\n",
            " |  \n",
            " |  do_lower_case = False\n",
            " |  \n",
            " |  dynamic_quantize = False\n",
            " |  \n",
            " |  early_stopping_consider_epochs = False\n",
            " |  \n",
            " |  early_stopping_delta = 0\n",
            " |  \n",
            " |  early_stopping_metric = 'eval_loss'\n",
            " |  \n",
            " |  early_stopping_metric_minimize = True\n",
            " |  \n",
            " |  early_stopping_patience = 3\n",
            " |  \n",
            " |  encoding = None\n",
            " |  \n",
            " |  eval_batch_size = 8\n",
            " |  \n",
            " |  evaluate_during_training = False\n",
            " |  \n",
            " |  evaluate_during_training_silent = True\n",
            " |  \n",
            " |  evaluate_during_training_steps = 2000\n",
            " |  \n",
            " |  evaluate_during_training_verbose = False\n",
            " |  \n",
            " |  evaluate_each_epoch = True\n",
            " |  \n",
            " |  fp16 = True\n",
            " |  \n",
            " |  gradient_accumulation_steps = 1\n",
            " |  \n",
            " |  local_rank = -1\n",
            " |  \n",
            " |  logging_steps = 50\n",
            " |  \n",
            " |  manual_seed = None\n",
            " |  \n",
            " |  max_grad_norm = 1.0\n",
            " |  \n",
            " |  max_seq_length = 128\n",
            " |  \n",
            " |  model_name = None\n",
            " |  \n",
            " |  model_type = None\n",
            " |  \n",
            " |  multiprocessing_chunksize = -1\n",
            " |  \n",
            " |  n_gpu = 1\n",
            " |  \n",
            " |  no_cache = False\n",
            " |  \n",
            " |  no_save = False\n",
            " |  \n",
            " |  num_train_epochs = 1\n",
            " |  \n",
            " |  output_dir = 'outputs/'\n",
            " |  \n",
            " |  overwrite_output_dir = False\n",
            " |  \n",
            " |  polynomial_decay_schedule_lr_end = 1e-07\n",
            " |  \n",
            " |  polynomial_decay_schedule_power = 1.0\n",
            " |  \n",
            " |  quantized_model = False\n",
            " |  \n",
            " |  reprocess_input_data = True\n",
            " |  \n",
            " |  save_best_model = True\n",
            " |  \n",
            " |  save_eval_checkpoints = True\n",
            " |  \n",
            " |  save_model_every_epoch = True\n",
            " |  \n",
            " |  save_optimizer_and_scheduler = True\n",
            " |  \n",
            " |  save_steps = 2000\n",
            " |  \n",
            " |  silent = False\n",
            " |  \n",
            " |  skip_special_tokens = True\n",
            " |  \n",
            " |  tensorboard_dir = None\n",
            " |  \n",
            " |  thread_count = None\n",
            " |  \n",
            " |  tokenizer_name = None\n",
            " |  \n",
            " |  tokenizer_type = None\n",
            " |  \n",
            " |  train_batch_size = 8\n",
            " |  \n",
            " |  train_custom_parameters_only = False\n",
            " |  \n",
            " |  use_cached_eval_features = False\n",
            " |  \n",
            " |  use_early_stopping = False\n",
            " |  \n",
            " |  use_hf_datasets = False\n",
            " |  \n",
            " |  use_multiprocessing = True\n",
            " |  \n",
            " |  use_multiprocessing_for_evaluation = True\n",
            " |  \n",
            " |  wandb_project = None\n",
            " |  \n",
            " |  warmup_ratio = 0.06\n",
            " |  \n",
            " |  warmup_steps = 0\n",
            " |  \n",
            " |  weight_decay = 0.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3G4lUePijm0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "71a62f5b53c4405191b6b98d1eabe576",
            "0397f0a559d841bf981389d7f812e392",
            "e5c704a5a1674eacb71db22be453575f",
            "3e83e18df2764f9da2e4f59eea1d7374",
            "30c789861ead4c83b59034d89f7469d8",
            "8eb7559e5aa74e7db9f0bbc59b807c14",
            "cbd59b07854946a593730d2ed98afcbe",
            "ccb96cc9ae14420298302d75a3d80513",
            "f3717bbcaa8742449858347516d21a62",
            "8c477172a7124ccf92eb41c97581281f",
            "a9988c6998d74be09b21b411b5d99142",
            "c8288ddcad5d43dfbc7f7c103856754b",
            "db45aea46b4f42568937d8ad354268d6",
            "390feb660ab84964b920af22593c36ce",
            "4d0d145fd6d047448e943358f44fa896",
            "d7623fea3c844fcb875417cf34114ecf",
            "1cad7e763e374d868b95518eb9b1874c",
            "2a14d77929a44b609afd4b6a1a9cb1d3",
            "6de1d4a1ea294bccaef113d99cc2162b",
            "da5e503f0e0b439686656f11f7d676b4",
            "aa791488108a4d6da31775ae560a14b3",
            "5cec73289665478e9249d4a282ba52e4",
            "70b0809374a244a38272feab285b84ec",
            "8371da6918064dee8b4eee6d420e8e72",
            "cc5f8766ecc3430bb9d1276bde24ad29",
            "783e2fd6a38c44e59aecb320aa0d5b01",
            "0c4e35850d184c7080f99f3fefd99f8c",
            "65f00143409c4420a906635c02822ea7",
            "9394e89f1cbc456c9854f90f8e6ae3d8",
            "a7b76636311048f9aa25e83c9d80bd39",
            "952de5fde21a44d3a9146a366e892476",
            "232d8773d5c34a9daa3badb1292982df",
            "34481195bb25481fabe381226a8c95df",
            "8d7b8f4e3caf4b02a85998dde53df922",
            "5dd76f20877849e4b24648b29ed047df",
            "aac3529404544f7a9a020911e45c2164",
            "890a275ec6bc452c99e6b08ab542fd6d",
            "d35f10c7b3eb48c59bf285089d9834ac",
            "67a6238c3a754133bab1187d023ac596",
            "edb2515a768b4b70b39268f8a64e73c2",
            "da41c805b5304e508030cad0cd8cd4da",
            "a08d734c26e440699cda73a189491968",
            "2821a3b85d034b1f81578ffb59fc8a58",
            "7ac9ce5d7f4f4759a9e189d5449dee36"
          ]
        },
        "outputId": "fdd056bb-05cd-42f6-fb64-4aea1d36fb44"
      },
      "source": [
        "## Create a simple transformers T5Model\n",
        "model = T5Model(\"t5\", \n",
        "                  \"t5-base\", \n",
        "                  args=model_args,\n",
        "                  use_cuda=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71a62f5b53c4405191b6b98d1eabe576",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8288ddcad5d43dfbc7f7c103856754b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70b0809374a244a38272feab285b84ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d7b8f4e3caf4b02a85998dde53df922",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kx_xRzJ4DIL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf42a224-f3b3-4eae-bcf7-447e0215bed6"
      },
      "source": [
        "## Print additional information about T5 model to console\n",
        "help(model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on T5Model in module simpletransformers.t5.t5_model object:\n",
            "\n",
            "class T5Model(builtins.object)\n",
            " |  T5Model(model_type, model_name, args=None, tokenizer=None, use_cuda=True, cuda_device=-1, **kwargs)\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, model_type, model_name, args=None, tokenizer=None, use_cuda=True, cuda_device=-1, **kwargs)\n",
            " |      Initializes a T5Model model.\n",
            " |      \n",
            " |      Args:\n",
            " |          model_type: The type of model (t5, mt5)\n",
            " |          model_name: The exact architecture and trained weights to use. This may be a Hugging Face Transformers compatible pre-trained model, a community model, or the path to a directory containing model files.\n",
            " |          args (optional): Default args will be used if this parameter is not provided. If provided, it should be a dict containing the args that should be changed in the default args.\n",
            " |          use_cuda (optional): Use GPU if available. Setting to False will force model to use CPU only.\n",
            " |          cuda_device (optional): Specific GPU that should be used. Will use the first available GPU by default.\n",
            " |          **kwargs (optional): For providing proxies, force_download, resume_download, cache_dir and other options specific to the 'from_pretrained' implementation where this will be supplied.\n",
            " |  \n",
            " |  compute_metrics(self, labels, preds, **kwargs)\n",
            " |      Computes the evaluation metrics for the model predictions.\n",
            " |      \n",
            " |      Args:\n",
            " |          labels: List of target sequences\n",
            " |          preds: List of model generated outputs\n",
            " |          **kwargs: Custom metrics that should be used. Pass in the metrics as keyword arguments (name of metric: function to use).\n",
            " |                      A metric function should take in two parameters. The first parameter will be the true labels, and the second parameter will be the predictions. Both inputs\n",
            " |                      will be lists of strings. Note that this will slow down evaluation significantly as the predicted sequences need to be generated.\n",
            " |      \n",
            " |      Returns:\n",
            " |          result: Dictionary containing evaluation results.\n",
            " |  \n",
            " |  eval_model(self, eval_data, output_dir=None, verbose=True, silent=False, **kwargs)\n",
            " |      Evaluates the model on eval_data. Saves results to output_dir.\n",
            " |      \n",
            " |      Args:\n",
            " |          eval_data: Pandas DataFrame containing the 3 columns - `prefix`, `input_text`, `target_text`.\n",
            " |                      - `prefix`: A string indicating the task to perform. (E.g. `\"question\"`, `\"stsb\"`)\n",
            " |                      - `input_text`: The input text sequence. `prefix` is automatically prepended to form the full input. (<prefix>: <input_text>)\n",
            " |                      - `target_text`: The target sequence\n",
            " |          output_dir: The directory where model files will be saved. If not given, self.args.output_dir will be used.\n",
            " |          verbose: If verbose, results will be printed to the console on completion of evaluation.\n",
            " |          silent: If silent, tqdm progress bars will be hidden.\n",
            " |          **kwargs: Additional metrics that should be used. Pass in the metrics as keyword arguments (name of metric: function to use).\n",
            " |                      A metric function should take in two parameters. The first parameter will be the true labels, and the second parameter will be the predictions. Both inputs\n",
            " |                      will be lists of strings. Note that this will slow down evaluation significantly as the predicted sequences need to be generated.\n",
            " |      Returns:\n",
            " |          results: Dictionary containing evaluation results.\n",
            " |  \n",
            " |  evaluate(self, eval_dataset, output_dir, verbose=True, silent=False, **kwargs)\n",
            " |      Evaluates the model on eval_dataset.\n",
            " |      \n",
            " |      Utility function to be used by the eval_model() method. Not intended to be used directly.\n",
            " |  \n",
            " |  get_named_parameters(self)\n",
            " |  \n",
            " |  load_and_cache_examples(self, data, evaluate=False, no_cache=False, verbose=True, silent=False)\n",
            " |      Creates a T5Dataset from data.\n",
            " |      \n",
            " |      Utility function for train() and eval() methods. Not intended to be used directly.\n",
            " |  \n",
            " |  predict(self, to_predict)\n",
            " |      Performs predictions on a list of text.\n",
            " |      \n",
            " |      Args:\n",
            " |          to_predict: A python list of text (str) to be sent to the model for prediction. Note that the prefix should be prepended to the text.\n",
            " |      \n",
            " |      Returns:\n",
            " |          preds: A python list of the generated sequences.\n",
            " |  \n",
            " |  save_model(self, output_dir=None, optimizer=None, scheduler=None, model=None, results=None)\n",
            " |  \n",
            " |  save_model_args(self, output_dir)\n",
            " |  \n",
            " |  train(self, train_dataset, output_dir, show_running_loss=True, eval_data=None, verbose=True, **kwargs)\n",
            " |      Trains the model on train_dataset.\n",
            " |      \n",
            " |      Utility function to be used by the train_model() method. Not intended to be used directly.\n",
            " |  \n",
            " |  train_model(self, train_data, output_dir=None, show_running_loss=True, args=None, eval_data=None, verbose=True, **kwargs)\n",
            " |      Trains the model using 'train_data'\n",
            " |      \n",
            " |      Args:\n",
            " |          train_data: Pandas DataFrame containing the 3 columns - `prefix`, `input_text`, `target_text`.\n",
            " |                      - `prefix`: A string indicating the task to perform. (E.g. `\"question\"`, `\"stsb\"`)\n",
            " |                      - `input_text`: The input text sequence. `prefix` is automatically prepended to form the full input. (<prefix>: <input_text>)\n",
            " |                      - `target_text`: The target sequence\n",
            " |          output_dir: The directory where model files will be saved. If not given, self.args.output_dir will be used.\n",
            " |          show_running_loss (optional): Set to False to prevent running loss from being printed to console. Defaults to True.\n",
            " |          args (optional): Optional changes to the args dict of the model. Any changes made will persist for the model.\n",
            " |          eval_data (optional): A DataFrame against which evaluation will be performed when evaluate_during_training is enabled. Is required if evaluate_during_training is enabled.\n",
            " |          **kwargs: Additional metrics that should be used. Pass in the metrics as keyword arguments (name of metric: function to use).\n",
            " |                      A metric function should take in two parameters. The first parameter will be the true labels, and the second parameter will be the predictions. Both inputs\n",
            " |                      will be lists of strings. Note that this will slow down training significantly as the predicted sequences need to be generated.\n",
            " |      \n",
            " |      Returns:\n",
            " |          global_step: Number of global steps trained\n",
            " |          training_details: Average training loss if evaluate_during_training is False or full training progress scores if evaluate_during_training is True\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPYqfM6Tqvk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d3a9b5b-9381-4198-b230-eb40946aa0d8"
      },
      "source": [
        "# Train the simple transformers NER model\n",
        "import time\n",
        "t0 = time.time()\n",
        "model.train_model(train_data, eval_data=eval_data)\n",
        "t1 = time.time()\n",
        "runtime = t1 - t0\n",
        "runtime"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3260: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using Adafactor for T5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:562: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  exp_avg_sq_row.mul_(beta2t).add_(1.0 - beta2t, update.mean(dim=-1))\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1854.3823835849762"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0voaQ-vqvox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb0a3e0-a537-459a-ccf0-49f11d32246e"
      },
      "source": [
        "## Evaluate the model\n",
        "result = model.eval_model(eval_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3260: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ460ywkvEBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b23d246-76dc-4392-8bcd-f9c4fd8d2cc5"
      },
      "source": [
        "## Result is evaluation metric\n",
        "result"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 3.9549167806451972}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwLcZ-gkyYBC"
      },
      "source": [
        "## Make predictions with the model\n",
        "## Fun question indices may include: 0, 27,\n",
        "question = eval_data['input_text'].iloc[52]\n",
        "answer = eval_data['target_text'].iloc[52]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ciIzvjRu3Rzm",
        "outputId": "11c4cebf-ea35-4ac8-fb9c-1601276baf9e"
      },
      "source": [
        "## Print the question\n",
        "question"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1. how effective is renal duplex in detecting renal artery stenosis? 2. is magnetic resonance angiography superior to renal duplex in detecting renal artery stenosis?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ob1m-Rp63YXp",
        "outputId": "32af75c5-6454-4cdd-a1ab-4f71c99b6499"
      },
      "source": [
        "## Print the true answer (from Kumar/Collins)\n",
        "answer"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1. duplex scanning compared to arteriography is over 90% sensitive and specific. 2. yes, and this is now best practice for the diagnosis.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eyagVjf1uy0",
        "outputId": "5cc5e30f-07d7-42e3-e96a-e2b288e78a29"
      },
      "source": [
        "## Make predictions given input\n",
        "preds = model.predict(question)\n",
        "preds"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3260: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['1. how effective is this method? it has been used in 1 trial (winning both the domestic and international standards) in 1 trial. 2. how effective is it? ratings are 3.4.',\n",
              "  '1. how effective is the treatment? 1. effectiveness of ace inhibitors is assessed after x-ray. use a statin. it often helps, although sometimes not helpful. 2. ineffective: use a statin.',\n",
              "  '1. you are right in saying that the placebo works and that the placebo doesnât matter. 1. how effective the placebo is shown is unclear.'],\n",
              " ['renal duplex is a complex plexus containing sodium chloride ii, potassium ii, sodium ii or calcium duplex.',\n",
              "  'renal duplex consists of a renal component and a renal duplex occurs when there is renal deplexing.',\n",
              "  'renal duplex is a complex renal infarction that consists of a renal component consisting of calcium channel dihydrochloride (dh), pyruvate diuretic and thiamine containing phosphat'],\n",
              " ['detection of recurrence is now routine in almost all cases of recurrence.',\n",
              "  'the detection of recurrence in the detection of recurrence is now much more urgent. further reading kaplan nm, opie n (2007) recurrence in the detection of',\n",
              "  'detection of recurrence of infection requires no special screening.'],\n",
              " ['stenocarcinoma of the natriuretic artery is the most common finding. steroid clearance is a direct consequence of arterial emboli, which can lead to coronary artery blockage. arterial',\n",
              "  'arterial stenosis usually carries a high mortality and can result in permanent arterial damage. stenosis usually occurs in neuropathic venous disease and can be dangerous.',\n",
              "  'no. veneoprotective steroid injection into the supracutaneous arteries produces diarrhoea. dexamethasone 80 mg/kg single dose. steroid injection into the systemic arteries leads'],\n",
              " ['1. sisi is a highly active polysaccharide; magnetic vasoactive protein. 2. magnetic is a vasoactive protein.',\n",
              "  '1. sisi is 1. magnetic magnes. two types of sis occur: 1. sisii, qrsi, p. 347; sisii. 2. magnetic is',\n",
              "  'sis) 1. magnetic vasoactive protein ivsii is common in all types of sis. 2. magnetic vasoactive protein ii is a vasoactive substance'],\n",
              " ['resonance analogues of gamma radio transmitters. resonance analogues of sonic resonance carry greater resonance.',\n",
              "  'resonance analogue of the classical classical resonance analogue of the ct/mri. resonance can be seen in the tic resonance analogue.',\n",
              "  'resonance analogues of tic resonance an analogues of lt-rc0006, published in 1997.'],\n",
              " ['giography superieurophotography a p. 747.',\n",
              "  'giography superior giography superior giography superior giography superior giography superior giography superior giography superior giography superior',\n",
              "  'giography superior agiography superior agiography superior agiography superior agiography superior giography superior giography superior giography'],\n",
              " ['renal dupl is rare; renal dupl is present in 4 out of 5 renal duple fractions.',\n",
              "  'renal dupl, to renal dupl, renal dupl, to renal dupl, to renal infiltration, plasma reinduction or ivdg must be replaced by a renal pool of recombin',\n",
              "  'renal duple fractions or plasma protein ratios are 60 mmol/l (250 mg/dl) or to renal dupletion (250 mg/dl).'],\n",
              " ['detect detection of ex ex ex ex detects only minor damage to the dignitary duct wall, which may affect the detection of ex ex ducting material (drugs), e.g. the hair follicle',\n",
              "  'detects exacerbation of dna â detection (p. 112). detects exacerbation of tp mri ex p. 658.',\n",
              "  'ex ex detecting detects no other abnormalities in a pleural fluid detector such as a pleural fluid. this is useful when other methods are not available.'],\n",
              " ['renal artery stenosis is the first step in renal artery steroid elimination. having removed the renal artery stenosis factor (rna), the renal artery steroid is usually ste',\n",
              "  'renal artery steroid peptide 1â10 mmol/l (137 mg) or 2 mmol/l (134 mg/dl).',\n",
              "  'renal artery steroid clearance is assessed with renal plaque filtration (pressure gradient 3.6â3.9 mmhg) and renal artery filtration is monitored with renal artery filtration. steroid clearance and clearance of'],\n",
              " ['no; nosis nosis nosis nosis!',\n",
              "  'nosis is a quick sips of water. with a low-salt content, often in the gas bubble, the lonesome remains behind the counterbalance.',\n",
              "  'nosis nosis is a spleenless granulomatous fibre count. it is usually associated with a âshockâ.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynf7IFIx2Xfi"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtOLvUDp2XjM"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_Vcehfa2Xl5"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ilOYNQQyYHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537cb169-b62d-425a-8de3-25835e623924"
      },
      "source": [
        "#############################\n",
        "## Print system info\n",
        "#############################\n",
        "#!pip install sinfo\n",
        "#import sinfo from sinfo\n",
        "sinfo()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.\n",
            "-----\n",
            "google              NA\n",
            "matplotlib          3.2.2\n",
            "numpy               1.19.5\n",
            "pandas              1.1.5\n",
            "scipy               1.4.1\n",
            "simpletransformers  NA\n",
            "sinfo               0.3.4\n",
            "sklearn             0.22.2.post1\n",
            "-----\n",
            "IPython             5.5.0\n",
            "jupyter_client      5.3.5\n",
            "jupyter_core        4.7.1\n",
            "notebook            5.3.1\n",
            "-----\n",
            "Python 3.7.10 (default, May  3 2021, 02:48:31) [GCC 7.5.0]\n",
            "Linux-5.4.109+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2 logical CPU cores, x86_64\n",
            "-----\n",
            "Session information updated at 2021-06-04 12:33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBvoHHMf_jc3"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ek9ZdP0_jl6"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ny-W5NU_jtR"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1kOYtSM_kDI"
      },
      "source": [
        "###################################################################\n",
        "## Save the rendered .ipynb files to HTML to share with others\n",
        "###################################################################"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsf2ZRMj_Jgw"
      },
      "source": [
        "#from google.colab import drive \n",
        "#drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfNdMBY6ybd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0bc1ae9-c5c1-45a5-a59c-14407ebba870"
      },
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html 'gdrive/My Drive/Colab Notebooks/SimpleTransformers_BERT_NER_DEID_i2b2_2014_May2021.ipynb'"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook gdrive/My Drive/Colab Notebooks/SimpleTransformers_BERT_NER_DEID_i2b2_2014_May2021.ipynb to html\n",
            "[NbConvertApp] Writing 8755801 bytes to gdrive/My Drive/Colab Notebooks/SimpleTransformers_BERT_NER_DEID_i2b2_2014_May2021.html\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAwbzIvV-255"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}